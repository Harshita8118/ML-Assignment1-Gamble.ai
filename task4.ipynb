{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import tsfel\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Base path to the directory containing the folders\n",
    "base_path = \"Combined/Train\"  # Update this to the path where your folders are located\n",
    "\n",
    "# Define the folders and corresponding labels\n",
    "folders = {\n",
    "    'WALKING': 1,\n",
    "    'WALKING_UPSTAIRS': 2,\n",
    "    'WALKING_DOWNSTAIRS': 3,\n",
    "    'SITTING': 4,\n",
    "    'STANDING': 5,\n",
    "    'LAYING': 6\n",
    "}\n",
    "\n",
    "# Initialize lists to hold data and labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each folder and file to read the data\n",
    "for folder, label in folders.items():\n",
    "    folder_path = os.path.join(base_path, folder)  # Combine base path with the folder name\n",
    "    # List all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):  # Ensure we only read CSV files\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Calculate the total acceleration magnitude\n",
    "            df['total_acceleration'] = np.sqrt(df['accx']**2 + df['accy']**2 + df['accz']**2)\n",
    "            \n",
    "            # Append data to the data list\n",
    "            data_frames.append(df)\n",
    "            \n",
    "            # Append corresponding label to the labels list\n",
    "            labels.extend([label] * len(df))\n",
    "\n",
    "# Concatenate all data frames into one\n",
    "X_train = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Convert labels to a DataFrame\n",
    "y_train = pd.DataFrame(labels, columns=['Activity'])\n",
    "\n",
    "# Save combined data to CSV\n",
    "# X_train.to_csv('X_train_combined.csv', index=False)\n",
    "# y_train.to_csv('y_train_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Base path to the directory containing the folders\n",
    "base_path = \"Combined/Test\"  # Update this to the path where your folders are located\n",
    "\n",
    "# Define the folders and corresponding labels\n",
    "folders = {\n",
    "    'WALKING': 1,\n",
    "    'WALKING_UPSTAIRS': 2,\n",
    "    'WALKING_DOWNSTAIRS': 3,\n",
    "    'SITTING': 4,\n",
    "    'STANDING': 5,\n",
    "    'LAYING': 6\n",
    "}\n",
    "\n",
    "# Initialize lists to hold data and labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each folder and file to read the data\n",
    "for folder, label in folders.items():\n",
    "    folder_path = os.path.join(base_path, folder)  # Combine base path with the folder name\n",
    "    # List all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):  # Ensure we only read CSV files\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Calculate the total acceleration magnitude\n",
    "            df['total_acceleration'] = np.sqrt(df['accx']**2 + df['accy']**2 + df['accz']**2)\n",
    "            \n",
    "            # Append data to the data list\n",
    "            data_frames.append(df)\n",
    "            \n",
    "            # Append corresponding label to the labels list\n",
    "            labels.extend([label] * len(df))\n",
    "\n",
    "# Concatenate all data frames into one\n",
    "X_test = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Convert labels to a DataFrame\n",
    "y_test = pd.DataFrame(labels, columns=['Activity'])\n",
    "\n",
    "# Save combined data to CSV\n",
    "# X_test.to_csv('X_test_combined.csv', index=False)\n",
    "# y_test.to_csv('y_test_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188608, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of X_test:\n",
      "   ax (m/s^2)  ay (m/s^2)  az (m/s^2)  aT (m/s^2)\n",
      "0     -0.5037     -0.1326     -0.0406       0.522\n",
      "1     -0.2844     -0.2044     -0.0087       0.350\n",
      "2      0.1120     -0.3033      0.0481       0.327\n",
      "3      0.3042     -0.2945     -0.0081       0.423\n",
      "4      0.4825     -0.2595     -0.0304       0.549\n",
      "\n",
      "First few rows of y_test:\n",
      "   Activity\n",
      "0         6\n",
      "1         6\n",
      "2         6\n",
      "3         6\n",
      "4         6\n"
     ]
    }
   ],
   "source": [
    "# Define the label mapping\n",
    "activity_labels = {\n",
    "    'walking': 1,\n",
    "    'walkingupstair': 2,\n",
    "    'walkingdownstair': 3,\n",
    "    'sitting': 4,\n",
    "    'standing': 5,\n",
    "    'laying': 6\n",
    "}\n",
    "\n",
    "# List all CSV files in the directory\n",
    "file_paths = glob.glob('data_scripts/our_data/*.csv')\n",
    "\n",
    "# Initialize empty lists to store the data and labels\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file_path in file_paths:\n",
    "    # Extract the activity name from the file name\n",
    "    file_name = file_path.split('/')[-1].lower()\n",
    "    activity_name = file_name.split('_')[-1].replace('.csv', '')\n",
    "\n",
    "    # Determine the label for the activity\n",
    "    label = activity_labels.get(activity_name)\n",
    "    \n",
    "    if label is not None:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Take only alternate rows and limit to 500 rows\n",
    "        \n",
    "        \n",
    "        # Add the data and corresponding label to the lists\n",
    "        X_test_list.append(df)\n",
    "        y_test_list.extend([label] * len(df))\n",
    "\n",
    "# Concatenate all dataframes to form X_test\n",
    "X_test = pd.concat(X_test_list, ignore_index=True)\n",
    "\n",
    "# Convert the labels list to a DataFrame to form y_test\n",
    "y_test = pd.DataFrame(y_test_list, columns=['Activity'])\n",
    "\n",
    "# Remove the 'time' column from X_train if it exists\n",
    "if 'time' in X_test.columns:\n",
    "    X_test = X_test.drop(columns=['time'])\n",
    "\n",
    "# Example: Displaying the first few rows of X_test and y_test\n",
    "print(\"First few rows of X_test:\")\n",
    "print(X_test.head())\n",
    "\n",
    "print(\"\\nFirst few rows of y_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax (m/s^2)</th>\n",
       "      <th>ay (m/s^2)</th>\n",
       "      <th>az (m/s^2)</th>\n",
       "      <th>aT (m/s^2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5037</td>\n",
       "      <td>-0.1326</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1120</td>\n",
       "      <td>-0.3033</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4825</td>\n",
       "      <td>-0.2595</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5082</td>\n",
       "      <td>-0.2226</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>-1.0919</td>\n",
       "      <td>-1.6690</td>\n",
       "      <td>-0.8239</td>\n",
       "      <td>2.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>-0.5762</td>\n",
       "      <td>-1.4886</td>\n",
       "      <td>-0.9101</td>\n",
       "      <td>1.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>-0.1972</td>\n",
       "      <td>-1.0017</td>\n",
       "      <td>-0.4554</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>-0.4641</td>\n",
       "      <td>-0.0419</td>\n",
       "      <td>-0.1781</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>-0.9033</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ax (m/s^2)  ay (m/s^2)  az (m/s^2)  aT (m/s^2)\n",
       "0         -0.5037     -0.1326     -0.0406       0.522\n",
       "1          0.1120     -0.3033      0.0481       0.327\n",
       "2          0.4825     -0.2595     -0.0304       0.549\n",
       "3          0.4833     -0.2023      0.2009       0.561\n",
       "4          0.5082     -0.2226      0.5205       0.761\n",
       "...           ...         ...         ...         ...\n",
       "11995     -1.0919     -1.6690     -0.8239       2.158\n",
       "11996     -0.5762     -1.4886     -0.9101       1.838\n",
       "11997     -0.1972     -1.0017     -0.4554       1.118\n",
       "11998     -0.4641     -0.0419     -0.1781       0.499\n",
       "11999     -0.9033      0.2427      0.1394       0.946\n",
       "\n",
       "[12000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the label mapping\n",
    "activity_labels = {\n",
    "    'walking': 1,\n",
    "    'walkingupstair': 2,\n",
    "    'walkingdownstair': 3,\n",
    "    'sitting': 4,\n",
    "    'standing': 5,\n",
    "    'laying': 6\n",
    "}\n",
    "\n",
    "# List all CSV files in the directory\n",
    "file_paths = glob.glob('data_scripts/our_data/*.csv')\n",
    "\n",
    "# Initialize empty lists to store the data and labels\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "# Function to resample data to 50 Hz\n",
    "def resample_to_50hz(df):\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.set_index('time').resample('20ms').mean().interpolate()\n",
    "    return df\n",
    "\n",
    "# Iterate through each file\n",
    "for file_path in file_paths:\n",
    "    # Extract the activity name from the file name\n",
    "    \n",
    "    file_name = file_path.split('/')[-1].lower()\n",
    "    activity_name = file_name.split('_')[-1].replace('.csv', '')\n",
    "\n",
    "    # Determine the label for the activity\n",
    "    label = activity_labels.get(activity_name)\n",
    "    \n",
    "    if label is not None:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Take only alternate rows but make sure to keep a minimum of rows\n",
    "        if len(df) >= 500:\n",
    "            df = df.iloc[::2, :].head(500)\n",
    "        else:\n",
    "            df = df.iloc[::2, :]  # keep all rows if less than 500\n",
    "        \n",
    "        # Add the resampled data and corresponding label to the lists\n",
    "        # print(\"Appending: \",file_path)\n",
    "        X_test_list.append(df)\n",
    "        y_test_list.extend([label] * len(df))\n",
    "\n",
    "# Concatenate all dataframes to form X_test\n",
    "X_test = pd.concat(X_test_list, ignore_index=True)\n",
    "\n",
    "# Convert the labels list to a DataFrame to form y_test\n",
    "y_test = pd.DataFrame(y_test_list, columns=['Activity'])\n",
    "\n",
    "# Remove the 'time' column from X_test if it exists\n",
    "if 'time' in X_test.columns:\n",
    "    X_test = X_test.drop(columns=['time'])\n",
    "\n",
    "# # Example: Displaying the first few rows of X_test and y_test\n",
    "# print(\"First few rows of X_test:\")\n",
    "# print(X_test.head())\n",
    "\n",
    "# print(\"\\nFirst few rows of y_test:\")\n",
    "# print(y_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity\n",
       "0             6\n",
       "1             6\n",
       "2             6\n",
       "3             6\n",
       "4             6\n",
       "...         ...\n",
       "11995         2\n",
       "11996         2\n",
       "11997         2\n",
       "11998         2\n",
       "11999         2\n",
       "\n",
       "[12000 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax (m/s^2)</th>\n",
       "      <th>ay (m/s^2)</th>\n",
       "      <th>az (m/s^2)</th>\n",
       "      <th>aT (m/s^2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5037</td>\n",
       "      <td>-0.1326</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1120</td>\n",
       "      <td>-0.3033</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4825</td>\n",
       "      <td>-0.2595</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5082</td>\n",
       "      <td>-0.2226</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>-1.0919</td>\n",
       "      <td>-1.6690</td>\n",
       "      <td>-0.8239</td>\n",
       "      <td>2.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>-0.5762</td>\n",
       "      <td>-1.4886</td>\n",
       "      <td>-0.9101</td>\n",
       "      <td>1.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>-0.1972</td>\n",
       "      <td>-1.0017</td>\n",
       "      <td>-0.4554</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>-0.4641</td>\n",
       "      <td>-0.0419</td>\n",
       "      <td>-0.1781</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>-0.9033</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ax (m/s^2)  ay (m/s^2)  az (m/s^2)  aT (m/s^2)\n",
       "0         -0.5037     -0.1326     -0.0406       0.522\n",
       "1          0.1120     -0.3033      0.0481       0.327\n",
       "2          0.4825     -0.2595     -0.0304       0.549\n",
       "3          0.4833     -0.2023      0.2009       0.561\n",
       "4          0.5082     -0.2226      0.5205       0.761\n",
       "...           ...         ...         ...         ...\n",
       "11995     -1.0919     -1.6690     -0.8239       2.158\n",
       "11996     -0.5762     -1.4886     -0.9101       1.838\n",
       "11997     -0.1972     -1.0017     -0.4554       1.118\n",
       "11998     -0.4641     -0.0419     -0.1781       0.499\n",
       "11999     -0.9033      0.2427      0.1394       0.946\n",
       "\n",
       "[12000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset column names to default integer-based indices\n",
    "X_test.columns = range(X_test.shape[1])\n",
    "X_train.columns = range(X_train.shape[1])\n",
    "y_test.columns = range(y_test.shape[1])\n",
    "y_train.columns = range(y_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax (m/s^2)</th>\n",
       "      <th>ay (m/s^2)</th>\n",
       "      <th>az (m/s^2)</th>\n",
       "      <th>aT (m/s^2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5037</td>\n",
       "      <td>-0.1326</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1120</td>\n",
       "      <td>-0.3033</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4825</td>\n",
       "      <td>-0.2595</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5082</td>\n",
       "      <td>-0.2226</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>-1.0919</td>\n",
       "      <td>-1.6690</td>\n",
       "      <td>-0.8239</td>\n",
       "      <td>2.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>-0.5762</td>\n",
       "      <td>-1.4886</td>\n",
       "      <td>-0.9101</td>\n",
       "      <td>1.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>-0.1972</td>\n",
       "      <td>-1.0017</td>\n",
       "      <td>-0.4554</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>-0.4641</td>\n",
       "      <td>-0.0419</td>\n",
       "      <td>-0.1781</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>-0.9033</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ax (m/s^2)  ay (m/s^2)  az (m/s^2)  aT (m/s^2)\n",
       "0         -0.5037     -0.1326     -0.0406       0.522\n",
       "1          0.1120     -0.3033      0.0481       0.327\n",
       "2          0.4825     -0.2595     -0.0304       0.549\n",
       "3          0.4833     -0.2023      0.2009       0.561\n",
       "4          0.5082     -0.2226      0.5205       0.761\n",
       "...           ...         ...         ...         ...\n",
       "11995     -1.0919     -1.6690     -0.8239       2.158\n",
       "11996     -0.5762     -1.4886     -0.9101       1.838\n",
       "11997     -0.1972     -1.0017     -0.4554       1.118\n",
       "11998     -0.4641     -0.0419     -0.1781       0.499\n",
       "11999     -0.9033      0.2427      0.1394       0.946\n",
       "\n",
       "[12000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 5, 1, 3, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09\n",
      "Precision: 0.10\n",
      "Recall: 0.09\n",
      "Confusion Matrix:\n",
      "[[ 116  292  500   12    0 1080]\n",
      " [ 119  309  592    7    0  973]\n",
      " [  69  216  569    4    0 1142]\n",
      " [  90   88 1800    0    0   22]\n",
      " [ 149  129 1634    0    0   88]\n",
      " [  51   85 1806    0    0   58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.06      0.09      2000\n",
      "           2       0.28      0.15      0.20      2000\n",
      "           3       0.08      0.28      0.13      2000\n",
      "           4       0.00      0.00      0.00      2000\n",
      "           5       0.00      0.00      0.00      2000\n",
      "           6       0.02      0.03      0.02      2000\n",
      "\n",
      "    accuracy                           0.09     12000\n",
      "   macro avg       0.10      0.09      0.07     12000\n",
      "weighted avg       0.10      0.09      0.07     12000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\OneDrive\\VS\\ES335_assignment_1\\ML-Assignment-Gamble.ai\\.conda\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\SIDDHARTH\\OneDrive\\VS\\ES335_assignment_1\\ML-Assignment-Gamble.ai\\.conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\SIDDHARTH\\OneDrive\\VS\\ES335_assignment_1\\ML-Assignment-Gamble.ai\\.conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\SIDDHARTH\\OneDrive\\VS\\ES335_assignment_1\\ML-Assignment-Gamble.ai\\.conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\SIDDHARTH\\OneDrive\\VS\\ES335_assignment_1\\ML-Assignment-Gamble.ai\\.conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the training and test data\n",
    "X_train = pd.read_csv('X_train_combined.csv')\n",
    "y_train = pd.read_csv('y_train_combined.csv')\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the label mapping\n",
    "activity_labels = {\n",
    "    'walking': 1,\n",
    "    'walkingupstair': 2,\n",
    "    'walkingdownstair': 3,\n",
    "    'sitting': 4,\n",
    "    'standing': 5,\n",
    "    'laying': 6\n",
    "}\n",
    "\n",
    "# List all CSV files in the directory\n",
    "file_paths = glob.glob('data_scripts/our_data/*.csv')\n",
    "\n",
    "# Initialize empty lists to store the data and labels\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Function to extract features from a DataFrame\n",
    "def extract_features(df):\n",
    "    features = {}\n",
    "    for col in df.columns:\n",
    "        features[f'{col}_mean'] = df[col].mean()\n",
    "        features[f'{col}_std'] = df[col].std()\n",
    "        features[f'{col}_min'] = df[col].min()\n",
    "        features[f'{col}_max'] = df[col].max()\n",
    "        features[f'{col}_skew'] = skew(df[col])\n",
    "        features[f'{col}_kurtosis'] = kurtosis(df[col])\n",
    "        features[f'{col}_median'] = df[col].median()\n",
    "        features[f'{col}_iqr'] = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "    return features\n",
    "\n",
    "# Iterate through each file\n",
    "for file_path in file_paths:\n",
    "    file_name = file_path.split('/')[-1].lower()\n",
    "    activity_name = file_name.split('_')[-1].replace('.csv', '')\n",
    "    label = activity_labels.get(activity_name)\n",
    "    \n",
    "    if label is not None:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if 'time' in df.columns:\n",
    "            df = df.drop(columns=['time'])\n",
    "        \n",
    "        # Extract features for each window of 100 samples (2 seconds at 50Hz)\n",
    "        for i in range(0, len(df), 100):\n",
    "            window = df.iloc[i:i+100]\n",
    "            if len(window) == 100:  # only use full windows\n",
    "                features = extract_features(window)\n",
    "                X_list.append(features)\n",
    "                y_list.append(label)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X = pd.DataFrame(X_list)\n",
    "y = pd.Series(y_list)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.7362637362637363\n",
      "Precision: 0.7448988772297044\n",
      "Recall: 0.7362637362637363\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12  4  1  0  0  0]\n",
      " [ 5  9  1  0  1  0]\n",
      " [ 2  1  7  0  0  0]\n",
      " [ 0  0  0 13  3  0]\n",
      " [ 0  0  0  2 13  1]\n",
      " [ 0  1  0  0  2 13]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.71      0.67        17\n",
      "           2       0.60      0.56      0.58        16\n",
      "           3       0.78      0.70      0.74        10\n",
      "           4       0.87      0.81      0.84        16\n",
      "           5       0.68      0.81      0.74        16\n",
      "           6       0.93      0.81      0.87        16\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.75      0.73      0.74        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test_scaled)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's performance has improved dramatically. A 73.63% accuracy for a 6-class problem is quite good, especially considering the complexity of human activity recognition tasks. The model is now able to distinguish between all activities with reasonable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "Groq_token = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax (m/s^2)</th>\n",
       "      <th>ay (m/s^2)</th>\n",
       "      <th>az (m/s^2)</th>\n",
       "      <th>aT (m/s^2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5037</td>\n",
       "      <td>-0.1326</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1120</td>\n",
       "      <td>-0.3033</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4825</td>\n",
       "      <td>-0.2595</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5082</td>\n",
       "      <td>-0.2226</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>-1.0919</td>\n",
       "      <td>-1.6690</td>\n",
       "      <td>-0.8239</td>\n",
       "      <td>2.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>-0.5762</td>\n",
       "      <td>-1.4886</td>\n",
       "      <td>-0.9101</td>\n",
       "      <td>1.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>-0.1972</td>\n",
       "      <td>-1.0017</td>\n",
       "      <td>-0.4554</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>-0.4641</td>\n",
       "      <td>-0.0419</td>\n",
       "      <td>-0.1781</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>-0.9033</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ax (m/s^2)  ay (m/s^2)  az (m/s^2)  aT (m/s^2)\n",
       "0         -0.5037     -0.1326     -0.0406       0.522\n",
       "1          0.1120     -0.3033      0.0481       0.327\n",
       "2          0.4825     -0.2595     -0.0304       0.549\n",
       "3          0.4833     -0.2023      0.2009       0.561\n",
       "4          0.5082     -0.2226      0.5205       0.761\n",
       "...           ...         ...         ...         ...\n",
       "11995     -1.0919     -1.6690     -0.8239       2.158\n",
       "11996     -0.5762     -1.4886     -0.9101       1.838\n",
       "11997     -0.1972     -1.0017     -0.4554       1.118\n",
       "11998     -0.4641     -0.0419     -0.1781       0.499\n",
       "11999     -0.9033      0.2427      0.1394       0.946\n",
       "\n",
       "[12000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Activity\n",
       "0            6\n",
       "1            6\n",
       "500          4\n",
       "501          4\n",
       "1000         5\n",
       "1001         5\n",
       "1500         1\n",
       "1501         1\n",
       "2000         3\n",
       "2001         3\n",
       "2500         2\n",
       "2501         2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = y_test.groupby('Activity').head(2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "LLM Classification: A classification task!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "```\n",
      "Data: ax (m/s^2)   -0.5037\n",
      "ay (m/s^2)   -0.1326\n",
      "az (m/s^2)   -0.0406\n",
      "aT (m/s^2)    0.5220\n",
      "```\n",
      "Let's calculate the total acceleration:\n",
      "```\n",
      "total_acceleration = sqrt((-0.5037)^2 + (-0.1326)^2 + (-0.0406)^2) = 0.5220\n",
      "```\n",
      "Now, let's compare this data with the provided training data:\n",
      "\n",
      "* The total acceleration (0.5220) is closest to the total acceleration values in the Label: 3 data points (0.360116 and 0.424027).\n",
      "* The accx value (-0.5037) is similar to the accx values in the Label: 3 data points (0.285522 and 0.384624).\n",
      "* The accy and accz values (-0.1326 and -0.0406) are also similar to the corresponding values in the Label: 3 data points.\n",
      "\n",
      "Based on these similarities, I predict the label for the new data as:\n",
      "```\n",
      "Label: 3\n",
      "```\n",
      "Please note that this is a simple classification based on the provided data and might not be accurate in a real-world scenario, where more complex models and larger datasets are typically used.\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 4\n",
      "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "First, let's calculate the total acceleration (aT) from the given ax, ay, and az values:\n",
      "\n",
      "aT = sqrt(ax^2 + ay^2 + az^2) = sqrt(0.5082^2 + (-0.2226)^2 + 0.5205^2) = 0.7610 (matches the given value)\n",
      "\n",
      "Now, let's compare the new data with the provided training data:\n",
      "\n",
      "* The new data has a relatively high accx (ax) value and a moderate accz (az) value, which is similar to the patterns seen in Label 4.\n",
      "* The total acceleration (aT) value is also similar to the values seen in Label 4.\n",
      "\n",
      "Based on these similarities, I predict the label for the new data as:\n",
      "\n",
      "Label: 4\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 500\n",
      "LLM Classification: A classification task!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "```\n",
      "Data: ax (m/s^2)   -0.0665\n",
      "ay (m/s^2)   -0.0528\n",
      "az (m/s^2)    0.3650\n",
      "aT (m/s^2)    0.3750\n",
      "```\n",
      "Let's calculate the total acceleration:\n",
      "```\n",
      "total_acceleration = sqrt((-0.0665)^2 + (-0.0528)^2 + (0.3650)^2) = 0.3750\n",
      "```\n",
      "Now, let's compare this data with the provided training data. I'll focus on the total acceleration and the individual axis values.\n",
      "\n",
      "The total acceleration (0.3750) is closest to the total acceleration values in Label 4 (around 1.008).\n",
      "\n",
      "Looking at the individual axis values, I notice that:\n",
      "\n",
      "* ax is negative, similar to Label 6 (around -0.317749).\n",
      "* ay is negative, similar to Label 6 (around 0.709149).\n",
      "* az is positive, similar to Label 4 (around 0.459197).\n",
      "\n",
      "Considering these similarities, I'm going to take a guess:\n",
      "\n",
      "Label: 4\n",
      "\n",
      "Please let me know if I'm correct or not!\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 510\n",
      "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "First, let's calculate the total acceleration (aT) from the given values:\n",
      "\n",
      "aT = sqrt(ax^2 + ay^2 + az^2) = sqrt(0.1184^2 + (-0.1550)^2 + (-0.2233)^2) = 0.2960 (matches the given value)\n",
      "\n",
      "Now, let's compare the new data with the provided training data:\n",
      "\n",
      "* accx (ax) is closest to 0.285522 and 0.384624 from Label: 3\n",
      "* accy (ay) is closest to -0.212180 and -0.169020 from Label: 3\n",
      "* accz (az) is closest to -0.056036 and -0.057407 from Label: 3\n",
      "* total_acceleration (aT) is closest to 0.360116 and 0.424027 from Label: 3\n",
      "\n",
      "Based on these similarities, I predict the label for the new data as:\n",
      "\n",
      "Label: 3\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 1001\n",
      "LLM Classification: A classification task!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "\n",
      "Data: ax (m/s^2)   -0.4099\n",
      "ay (m/s^2)    0.1301\n",
      "az (m/s^2)    0.8049\n",
      "aT (m/s^2)    0.9130\n",
      "\n",
      "To classify this data, I'll compare it to the patterns in the provided data. After analyzing the values, I think the new data is most similar to the data with Label: 4.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The ax value (-0.4099) is closest to the accx values in the Label: 4 data (0.742314 and 0.754891).\n",
      "* The ay value (0.1301) is similar to the accy values in the Label: 4 data (0.494371 and 0.485327).\n",
      "* The az value (0.8049) is close to the accz values in the Label: 4 data (0.471142 and 0.459197).\n",
      "* The total acceleration (aT) value (0.9130) is similar to the total_acceleration values in the Label: 4 data (1.008667 and 1.008100).\n",
      "\n",
      "Based on these similarities, I predict the label for the new data as:\n",
      "\n",
      "Label: 4\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 1011\n",
      "LLM Classification: A classification task!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "\n",
      "Data: ax (m/s^2)   -0.0319\n",
      "ay (m/s^2)    0.0505\n",
      "az (m/s^2)   -0.2397\n",
      "aT (m/s^2)    0.2470\n",
      "\n",
      "To classify this data, I'll compare it with the patterns in the provided dataset. After analyzing the data, I think the new data is most similar to the data with Label: 3.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The accx value (-0.0319) is close to the values in the Label: 3 data (0.285522 and 0.384624).\n",
      "* The accy value (0.0505) is also similar to the values in the Label: 3 data (-0.212180 and -0.169020).\n",
      "* The accz value (-0.2397) is close to the values in the Label: 3 data (-0.056036 and -0.057407).\n",
      "* The total_acceleration value (0.2470) is similar to the values in the Label: 3 data (0.360116 and 0.424027).\n",
      "\n",
      "Based on these similarities, I predict the label for the new data as:\n",
      "\n",
      "Label: 3\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 1500\n",
      "LLM Classification: A classification problem!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "```\n",
      "Data: ax (m/s^2)   -0.3264\n",
      "ay (m/s^2)    0.1807\n",
      "az (m/s^2)    0.4227\n",
      "aT (m/s^2)    0.5640\n",
      "```\n",
      "Comparing this data with the provided training data, I notice some similarities with the data points labeled as 6. Specifically, the negative value of `ax` and the relatively high values of `ay` and `az` seem to match the patterns in the data points labeled as 6.\n",
      "\n",
      "Therefore, my prediction is:\n",
      "```\n",
      "Label: 6\n",
      "```\n",
      "Please let me know if this classification is correct or not!\n",
      "Actual Label: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 1520\n",
      "LLM Classification: A classification task!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "```\n",
      "Data: ax (m/s^2)   -0.0548\n",
      "ay (m/s^2)    0.0061\n",
      "az (m/s^2)    0.5320\n",
      "aT (m/s^2)    0.5350\n",
      "```\n",
      "Let's calculate the total acceleration:\n",
      "```\n",
      "total_acceleration = sqrt(ax^2 + ay^2 + az^2) = sqrt((-0.0548)^2 + 0.0061^2 + 0.5320^2) = 0.5350\n",
      "```\n",
      "Now, let's compare the new data with the provided data:\n",
      "\n",
      "* The total acceleration (0.5350) is closest to the total acceleration values in the Label: 4 data points (1.008667 and 1.008100).\n",
      "* The accx value (-0.0548) is similar to the accx values in the Label: 4 data points (0.742314 and 0.754891), which are also positive but closer to zero.\n",
      "* The accy value (0.0061) is relatively small, similar to the accy values in the Label: 4 data points (0.494371 and 0.485327), which are also positive.\n",
      "* The accz value (0.5320) is similar to the accz values in the Label: 4 data points (0.471142 and 0.459197), which are also positive.\n",
      "\n",
      "Based on these similarities, I predict the label for the new data as:\n",
      "```\n",
      "Label: 4\n",
      "```\n",
      "Please note that this classification is based on a simple analysis of the provided data and might not be accurate if there are other factors or features that are not considered here.\n",
      "Actual Label: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 2000\n",
      "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "First, let's calculate the total acceleration (aT) from the given values:\n",
      "\n",
      "aT = sqrt(ax^2 + ay^2 + az^2) = sqrt((-0.3451)^2 + (0.6854)^2 + (-0.1279)^2) ≈ 0.7780 (matches the given value)\n",
      "\n",
      "Now, let's compare the new data with the provided training data:\n",
      "\n",
      "* The new data has a similar pattern to the data with Label: 6, which has a negative accx, a positive accy, and a negative accz.\n",
      "\n",
      "Based on this similarity, I predict the label for the new data as:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 3\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 2020\n",
      "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "First, let's calculate the total acceleration (aT) from the given ax, ay, and az values:\n",
      "\n",
      "aT = sqrt(ax^2 + ay^2 + az^2) = sqrt(1.2337^2 + 0.1820^2 + (-0.0508)^2) = 1.2480 (matches the given value)\n",
      "\n",
      "Now, let's compare the new data with the provided training data:\n",
      "\n",
      "* The new data has a relatively high total acceleration (1.2480) and a high ax value (1.2337).\n",
      "* Among the training data, the closest match is the data with Label: 1, which also has high total acceleration and ax values.\n",
      "\n",
      "Based on this analysis, I predict the classification as:\n",
      "\n",
      "Label: 1\n",
      "Actual Label: 3\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 2500\n",
      "LLM Classification: A classification problem!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "```\n",
      "Data: ax (m/s^2)   -0.8288\n",
      "ay (m/s^2)   -0.6472\n",
      "az (m/s^2)    1.2435\n",
      "aT (m/s^2)    1.6290\n",
      "```\n",
      "Let's compare this data with the provided training data.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "1. The `ax` value is negative, which is similar to the `accx` values in Labels 6.\n",
      "2. The `ay` value is also negative, which is consistent with Labels 6.\n",
      "3. The `az` value is positive, which is similar to the `accz` values in Labels 6.\n",
      "4. The `aT` value (total acceleration) is relatively high, which is similar to the `total_acceleration` values in Labels 6.\n",
      "\n",
      "**Classification:**\n",
      "Based on these observations, I predict that the new data belongs to:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 2\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 2550\n",
      "LLM Classification: A classification problem!\n",
      "\n",
      "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "Here's the new data:\n",
      "```\n",
      "Data: ax (m/s^2)   -0.5327\n",
      "ay (m/s^2)    1.7472\n",
      "az (m/s^2)    0.2030\n",
      "aT (m/s^2)    1.8380\n",
      "```\n",
      "Comparing this data with the provided training data, I notice that the `ay` value is quite high, which is similar to the patterns seen in Label 6. Additionally, the `aT` value is also relatively high, which further supports this classification.\n",
      "\n",
      "Therefore, my prediction is:\n",
      "```\n",
      "Label: 6\n",
      "```\n",
      "Please let me know if this is correct or not!\n",
      "Actual Label: 2\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import re\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "\n",
    "# Define the extract_label function\n",
    "def extract_label(llm_response):\n",
    "    \"\"\"Extract the predicted label from the LLM response.\"\"\"\n",
    "    match = re.search(r'(?i)label: (\\d+)', llm_response)  # The '(?i)' makes the search case-insensitive\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Sample indexes from your training set\n",
    "indexes = [1, 5, 95338, 95339, 165307, 165308, 273575, 273576, 315741, 315742, 407872, 407873]\n",
    "\n",
    "# def get_random_subset(row, subset_size=10):\n",
    "#     \"\"\"Returns a random subset of 'subset_size' elements from a row.\n",
    "#     If the row has fewer elements than 'subset_size', it will return all elements.\"\"\"\n",
    "#     if len(row) < subset_size:\n",
    "#         subset_size = len(row)  # Adjust subset_size to the available elements\n",
    "#     return row.sample(n=subset_size, random_state=1)\n",
    "\n",
    "\n",
    "# Prepare few-shot training examples using a small subset of each row\n",
    "few_shot_examples = []\n",
    "for index in indexes:\n",
    "    # Select a random subset of the row\n",
    "    subset_data = X_train.iloc[index]\n",
    "    data_str = subset_data.to_string()\n",
    "    actual_label = y_train.iloc[index].values[0]\n",
    "    few_shot_examples.append(f\"Data: {data_str}\\nLabel: {actual_label}\")\n",
    "\n",
    "# Concatenate the few-shot examples for the prompt\n",
    "few_shot_prompt = \"\\n\\n\".join(few_shot_examples)\n",
    "\n",
    "\n",
    "\n",
    "# Lists to store results\n",
    "llm_predictions = []\n",
    "decision_tree_predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "# Test the model on new data\n",
    "test_indexes = [0, 4, 500, 510, 1001, 1011, 1500,1520,2000,2020,2500,2550  ] # (6,4,5,1,3,2) one index is repeated\n",
    "\n",
    "for index in test_indexes:\n",
    "    # Select a random subset of the test row\n",
    "    subset_data = X_test.iloc[index]\n",
    "    data_str = subset_data.to_string()\n",
    "    query = (f\"{few_shot_prompt}\\n\\n\"\n",
    "             f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
    "             f\"Data: {data_str}\\n\\n\"\n",
    "             \"Please provide the classification in the following format:\\n\"\n",
    "             \"Label: <predicted_label>\")\n",
    "    \n",
    "    # Initialize and use the language model\n",
    "    model_name = \"llama3-70b\"  # Model name\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Extract the LLM prediction\n",
    "    llm_label = extract_label(answer.content.strip())\n",
    "    \n",
    "    # Store LLM prediction and actual label\n",
    "    llm_predictions.append(llm_label)\n",
    "    actual_labels.append(y_test.iloc[index].values[0])\n",
    "    \n",
    "    # Decision Tree prediction\n",
    "    # decision_tree_prediction = clf.predict([X_test.iloc[index]])[0]\n",
    "    # decision_tree_predictions.append(decision_tree_prediction)\n",
    "    \n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"LLM Classification: {answer.content.strip()}\")\n",
    "    print(f\"Actual Label: {y_test.iloc[index].values[0]}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "LLM Classification: After analyzing the provided accelerometer data, I'm going to classify it into the correct human activity.\n",
      "\n",
      "**Classification:**\n",
      "\n",
      "Label: 3\n",
      "Actual Label: 3\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 4\n",
      "LLM Classification: After analyzing the provided accelerometer data, I predict that it belongs to the following human activity:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 10\n",
      "LLM Classification: After analyzing the provided accelerometer data, I'm going to classify it into the correct human activity.\n",
      "\n",
      "**Classification:**\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 20\n",
      "LLM Classification: After analyzing the provided accelerometer data, I'm going to classify it into the correct human activity.\n",
      "\n",
      "**Classification:**\n",
      "\n",
      "Label: 2\n",
      "Actual Label: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 30\n",
      "LLM Classification: After analyzing the provided accelerometer data, I predict that it belongs to the following human activity:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 40\n",
      "LLM Classification: After analyzing the provided accelerometer data, I predict that it belongs to the following human activity:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 50\n",
      "LLM Classification: After analyzing the provided accelerometer data, I'm going to classify it into the correct human activity.\n",
      "\n",
      "**Classification:**\n",
      "\n",
      "Label: 3\n",
      "Actual Label: 2\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 60\n",
      "LLM Classification: After analyzing the provided accelerometer data, I predict that it belongs to the following human activity:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 70\n",
      "LLM Classification: After analyzing the provided accelerometer data, I'm going to classify it into the correct human activity.\n",
      "\n",
      "**Classification:**\n",
      "\n",
      "Label: 3\n",
      "Actual Label: 2\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 80\n",
      "LLM Classification: After analyzing the provided accelerometer data, I predict the following classification:\n",
      "\n",
      "Label: 3\n",
      "Actual Label: 2\n",
      "\n",
      "==================================================\n",
      "\n",
      "Accuracy: 0.30\n",
      "Precision: 0.11\n",
      "Recall: 0.30\n",
      "Confusion Matrix:\n",
      "[[0 1 0 0 0 0]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 2]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 2]]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\OneDrive\\VS\\ES335_assignment_1\\ML-Assignment-Gamble.ai\\.conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import re\n",
    "\n",
    "# Define the label mapping\n",
    "activity_labels = {\n",
    "    'walking': 1,\n",
    "    'walkingupstair': 2,\n",
    "    'walkingdownstair': 3,\n",
    "    'sitting': 4,\n",
    "    'standing': 5,\n",
    "    'laying': 6\n",
    "}\n",
    "\n",
    "# List all CSV files in the directory\n",
    "file_paths = glob.glob('data_scripts/our_data/*.csv')\n",
    "\n",
    "# Initialize empty lists to store the data and labels\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Function to extract features from a DataFrame\n",
    "def extract_features(df):\n",
    "    features = {}\n",
    "    for col in df.columns:\n",
    "        features[f'{col}_mean'] = df[col].mean()\n",
    "        features[f'{col}_std'] = df[col].std()\n",
    "        features[f'{col}_min'] = df[col].min()\n",
    "        features[f'{col}_max'] = df[col].max()\n",
    "        features[f'{col}_skew'] = skew(df[col])\n",
    "        features[f'{col}_kurtosis'] = kurtosis(df[col])\n",
    "        features[f'{col}_median'] = df[col].median()\n",
    "        features[f'{col}_iqr'] = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "    return features\n",
    "\n",
    "# Iterate through each file\n",
    "for file_path in file_paths:\n",
    "    file_name = file_path.split('/')[-1].lower()\n",
    "    activity_name = file_name.split('_')[-1].replace('.csv', '')\n",
    "    label = activity_labels.get(activity_name)\n",
    "    \n",
    "    if label is not None:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if 'time' in df.columns:\n",
    "            df = df.drop(columns=['time'])\n",
    "        \n",
    "        # Extract features for each window of 100 samples (2 seconds at 50Hz)\n",
    "        for i in range(0, len(df), 100):\n",
    "            window = df.iloc[i:i+100]\n",
    "            if len(window) == 100:  # only use full windows\n",
    "                features = extract_features(window)\n",
    "                X_list.append(features)\n",
    "                y_list.append(label)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X = pd.DataFrame(X_list)\n",
    "y = pd.Series(y_list)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the extract_label function\n",
    "def extract_label(llm_response):\n",
    "    \"\"\"Extract the predicted label from the LLM response.\"\"\"\n",
    "    match = re.search(r'(?i)label: (\\d+)', llm_response)  # The '(?i)' makes the search case-insensitive\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Sample valid indexes from your training set\n",
    "num_train_samples = X_train_scaled.shape[0]\n",
    "indexes = np.random.choice(num_train_samples, size=12, replace=False)\n",
    "\n",
    "# Prepare few-shot training examples using a small subset of each row\n",
    "few_shot_examples = []\n",
    "for index in indexes:\n",
    "    # Select a random subset of the row\n",
    "    subset_data = pd.Series(X_train_scaled[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    actual_label = y_train.iloc[index]\n",
    "    few_shot_examples.append(f\"Data: {data_str}\\nLabel: {actual_label}\")\n",
    "\n",
    "# Concatenate the few-shot examples for the prompt\n",
    "few_shot_prompt = \"\\n\\n\".join(few_shot_examples)\n",
    "\n",
    "# Lists to store results\n",
    "llm_predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "# Test the model on new data\n",
    "test_indexes = [0, 4, 10, 20, 30, 40, 50, 60, 70, 80]  # Ensure these are valid indices\n",
    "\n",
    "# Validate test indexes to avoid out-of-bounds errors\n",
    "num_test_samples = X_test_scaled.shape[0]\n",
    "test_indexes = [i for i in test_indexes if i < num_test_samples]\n",
    "\n",
    "for index in test_indexes:\n",
    "    # Select a random subset of the test row\n",
    "    subset_data = pd.Series(X_test_scaled[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    query = (f\"{few_shot_prompt}\\n\\n\"\n",
    "             f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
    "             f\"Data: {data_str}\\n\\n\"\n",
    "             \"Please provide the classification in the following format:\\n\"\n",
    "             \"Label: <predicted_label>\")\n",
    "    \n",
    "    # Initialize and use the language model\n",
    "    model_name = \"llama3-70b\"  # Model name\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Extract the LLM prediction\n",
    "    llm_label = extract_label(answer.content.strip())\n",
    "    \n",
    "    # Store LLM prediction and actual label\n",
    "    llm_predictions.append(llm_label)\n",
    "    actual_labels.append(y_test.iloc[index])\n",
    "    \n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"LLM Classification: {answer.content.strip()}\")\n",
    "    print(f\"Actual Label: {y_test.iloc[index]}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Calculate and print metrics\n",
    "accuracy = accuracy_score(actual_labels, llm_predictions)\n",
    "precision = precision_score(actual_labels, llm_predictions, average='weighted')\n",
    "recall = recall_score(actual_labels, llm_predictions, average='weighted')\n",
    "conf_matrix = confusion_matrix(actual_labels, llm_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
