{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Dataframe (df_1):\n",
      "       time  ax (m/s^2)  ay (m/s^2)  az (m/s^2)  aT (m/s^2)\n",
      "0  0.001212     -0.3264      0.1807      0.4227       0.564\n",
      "2  0.025388     -0.1364      0.4233     -0.2279       0.500\n",
      "4  0.042872      0.5995     -0.1134      0.0656       0.614\n",
      "6  0.062871     -0.0867     -0.1208      0.1308       0.198\n",
      "8  0.082665     -0.3910     -0.1273      0.0310       0.412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# List all CSV files in the directory (assuming they are in the same folder)\n",
    "file_paths = glob.glob('data+scripts/our_data/*.csv')  # Add the wildcard to match all CSV files\n",
    "\n",
    "# Initialize an empty dictionary to store individual dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate through each file, read it, and store the first 500 alternate rows\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    df = pd.read_csv(file_path)  # Read the CSV file\n",
    "    df_alternate = df.iloc[::2, :].head(500)  # Take only alternate rows and limit to 500 rows\n",
    "    dataframes[f'df_{idx+1}'] = df_alternate  # Store the dataframe in the dictionary with a unique key\n",
    "\n",
    "# Example: Accessing the first dataframe\n",
    "print(\"First Dataframe (df_1):\")\n",
    "print(dataframes['df_1'].head())\n",
    "\n",
    "# Access other dataframes as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import tsfel\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_14952\\534280910.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs = {axis: pd.read_csv(file_paths[axis], header=None, delim_whitespace=True) for axis in axes}\n",
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_14952\\534280910.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs = {axis: pd.read_csv(file_paths[axis], header=None, delim_whitespace=True) for axis in axes}\n",
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_14952\\534280910.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs = {axis: pd.read_csv(file_paths[axis], header=None, delim_whitespace=True) for axis in axes}\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "axes = [\"x\", \"y\", \"z\"]\n",
    "file_paths = {axis: f\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/Inertial Signals/total_acc_{axis}_train.txt\" for axis in axes}\n",
    "\n",
    "# Load data for each axis into a dictionary of DataFrames\n",
    "dfs = {axis: pd.read_csv(file_paths[axis], header=None, delim_whitespace=True) for axis in axes}\n",
    "\n",
    "# Compute the magnitude of acceleration\n",
    "# Calculate sqrt(x^2 + y^2 + z^2) for each row\n",
    "df_acc = pd.DataFrame(np.sqrt(dfs['x']**2 + dfs['y']**2 + dfs['z']**2))\n",
    "\n",
    "# Optionally, save to a CSV file\n",
    "df_acc.to_csv(\"combined_total_acceleration.csv\", index=False, header=False)\n",
    "\n",
    "# Load the combined acceleration magnitude data for training\n",
    "df_train_acc = pd.read_csv(\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/__MACOSX/UCI HAR Dataset/train/Inertial Signals/combined_total_acceleration.csv\", header=None)\n",
    "# Load the labels for training data\n",
    "y_train = pd.read_csv(\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_14952\\1479076420.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n",
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_14952\\1479076420.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n",
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_14952\\1479076420.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n"
     ]
    }
   ],
   "source": [
    "# Load the combined acceleration magnitude data for testing (repeat the magnitude calculation process for test data)\n",
    "axes = [\"x\", \"y\", \"z\"]\n",
    "file_paths_test = {axis: f\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/Inertial Signals/total_acc_{axis}_test.txt\" for axis in axes}\n",
    "\n",
    "# Load data for each axis into a dictionary of DataFrames for the test set\n",
    "dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n",
    "\n",
    "# Compute the magnitude of acceleration for the test set\n",
    "df_test_acc = pd.DataFrame(np.sqrt(dfs_test['x']**2 + dfs_test['y']**2 + dfs_test['z']**2))\n",
    "\n",
    "# Load the labels for the test data\n",
    "y_test = pd.read_csv(\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(df_train_acc, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Predict the labels for the test set\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mdf_test_acc\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(df_train_acc, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(df_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, precision, recall, and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_12524\\3391091943.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n",
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_12524\\3391091943.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n",
      "C:\\Users\\SIDDHARTH\\AppData\\Local\\Temp\\ipykernel_12524\\3391091943.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n"
     ]
    }
   ],
   "source": [
    "# Load the combined acceleration magnitude data for testing (repeat the magnitude calculation process for test data)\n",
    "axes = [\"x\", \"y\", \"z\"]\n",
    "file_paths_test = {axis: f\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/Inertial Signals/total_acc_{axis}_test.txt\" for axis in axes}\n",
    "\n",
    "# Load data for each axis into a dictionary of DataFrames for the test set\n",
    "dfs_test = {axis: pd.read_csv(file_paths_test[axis], header=None, delim_whitespace=True) for axis in axes}\n",
    "\n",
    "# Compute the magnitude of acceleration for the test set\n",
    "df_test_acc = pd.DataFrame(np.sqrt(dfs_test['x']**2 + dfs_test['y']**2 + dfs_test['z']**2))\n",
    "\n",
    "# Load the labels for the test data\n",
    "y_test = pd.read_csv(\"data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(df_train_acc, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(df_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
