{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "Groq_token = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (7352, 561)\n",
      "y shape:  (7352, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the data from the text file into a pandas DataFrame\n",
    "X_train = pd.read_csv(\n",
    "    'data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt',\n",
    "    sep='\\s+', # white space as delimiter\n",
    "    header=None  # No header row in the file\n",
    ")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"X shape: \",X_train.shape)\n",
    "\n",
    "y_train=pd.read_csv(\n",
    "    'data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt',\n",
    "    header=None\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"y shape: \",y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>-0.330370</td>\n",
       "      <td>-0.705974</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401189</td>\n",
       "      <td>-0.121845</td>\n",
       "      <td>-0.594944</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>-0.190422</td>\n",
       "      <td>-0.640736</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116695</td>\n",
       "      <td>-0.344418</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.340134</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>-0.698954</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>-0.077108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121711</td>\n",
       "      <td>-0.534685</td>\n",
       "      <td>-0.846595</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>-0.118545</td>\n",
       "      <td>-0.692245</td>\n",
       "      <td>0.290722</td>\n",
       "      <td>-0.073857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>0.310155</td>\n",
       "      <td>-0.053391</td>\n",
       "      <td>-0.099109</td>\n",
       "      <td>-0.287866</td>\n",
       "      <td>-0.140589</td>\n",
       "      <td>-0.215088</td>\n",
       "      <td>-0.356083</td>\n",
       "      <td>-0.148775</td>\n",
       "      <td>-0.232057</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074472</td>\n",
       "      <td>-0.376278</td>\n",
       "      <td>-0.750809</td>\n",
       "      <td>-0.337422</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.884904</td>\n",
       "      <td>-0.698885</td>\n",
       "      <td>-0.651732</td>\n",
       "      <td>0.274627</td>\n",
       "      <td>0.184784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>0.363385</td>\n",
       "      <td>-0.039214</td>\n",
       "      <td>-0.105915</td>\n",
       "      <td>-0.305388</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>-0.196373</td>\n",
       "      <td>-0.373540</td>\n",
       "      <td>-0.030036</td>\n",
       "      <td>-0.270237</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101859</td>\n",
       "      <td>-0.320418</td>\n",
       "      <td>-0.700274</td>\n",
       "      <td>-0.736701</td>\n",
       "      <td>-0.372889</td>\n",
       "      <td>-0.657421</td>\n",
       "      <td>0.322549</td>\n",
       "      <td>-0.655181</td>\n",
       "      <td>0.273578</td>\n",
       "      <td>0.182412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>0.349966</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>-0.115788</td>\n",
       "      <td>-0.329638</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>-0.250181</td>\n",
       "      <td>-0.388017</td>\n",
       "      <td>-0.133257</td>\n",
       "      <td>-0.347029</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066249</td>\n",
       "      <td>-0.118854</td>\n",
       "      <td>-0.467179</td>\n",
       "      <td>-0.181560</td>\n",
       "      <td>0.088574</td>\n",
       "      <td>0.696663</td>\n",
       "      <td>0.363139</td>\n",
       "      <td>-0.655357</td>\n",
       "      <td>0.274479</td>\n",
       "      <td>0.181184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.237594</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>-0.096499</td>\n",
       "      <td>-0.323114</td>\n",
       "      <td>-0.229775</td>\n",
       "      <td>-0.207574</td>\n",
       "      <td>-0.392380</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>-0.289477</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046467</td>\n",
       "      <td>-0.205445</td>\n",
       "      <td>-0.617737</td>\n",
       "      <td>0.444558</td>\n",
       "      <td>-0.819188</td>\n",
       "      <td>0.929294</td>\n",
       "      <td>-0.008398</td>\n",
       "      <td>-0.659719</td>\n",
       "      <td>0.264782</td>\n",
       "      <td>0.187563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>0.153627</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.137018</td>\n",
       "      <td>-0.330046</td>\n",
       "      <td>-0.195253</td>\n",
       "      <td>-0.164339</td>\n",
       "      <td>-0.430974</td>\n",
       "      <td>-0.218295</td>\n",
       "      <td>-0.229933</td>\n",
       "      <td>-0.111527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010386</td>\n",
       "      <td>-0.072237</td>\n",
       "      <td>-0.436940</td>\n",
       "      <td>0.598808</td>\n",
       "      <td>-0.287951</td>\n",
       "      <td>0.876030</td>\n",
       "      <td>-0.024965</td>\n",
       "      <td>-0.660080</td>\n",
       "      <td>0.263936</td>\n",
       "      <td>0.188103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2947 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.257178 -0.023285 -0.014654 -0.938404 -0.920091 -0.667683 -0.952501   \n",
       "1     0.286027 -0.013163 -0.119083 -0.975415 -0.967458 -0.944958 -0.986799   \n",
       "2     0.275485 -0.026050 -0.118152 -0.993819 -0.969926 -0.962748 -0.994403   \n",
       "3     0.270298 -0.032614 -0.117520 -0.994743 -0.973268 -0.967091 -0.995274   \n",
       "4     0.274833 -0.027848 -0.129527 -0.993852 -0.967445 -0.978295 -0.994111   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2942  0.310155 -0.053391 -0.099109 -0.287866 -0.140589 -0.215088 -0.356083   \n",
       "2943  0.363385 -0.039214 -0.105915 -0.305388  0.028148 -0.196373 -0.373540   \n",
       "2944  0.349966  0.030077 -0.115788 -0.329638 -0.042143 -0.250181 -0.388017   \n",
       "2945  0.237594  0.018467 -0.096499 -0.323114 -0.229775 -0.207574 -0.392380   \n",
       "2946  0.153627 -0.018437 -0.137018 -0.330046 -0.195253 -0.164339 -0.430974   \n",
       "\n",
       "           7         8         9    ...       551       552       553  \\\n",
       "0    -0.925249 -0.674302 -0.894088  ...  0.071645 -0.330370 -0.705974   \n",
       "1    -0.968401 -0.945823 -0.894088  ... -0.401189 -0.121845 -0.594944   \n",
       "2    -0.970735 -0.963483 -0.939260  ...  0.062891 -0.190422 -0.640736   \n",
       "3    -0.974471 -0.968897 -0.938610  ...  0.116695 -0.344418 -0.736124   \n",
       "4    -0.965953 -0.977346 -0.938610  ... -0.121711 -0.534685 -0.846595   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2942 -0.148775 -0.232057  0.185361  ...  0.074472 -0.376278 -0.750809   \n",
       "2943 -0.030036 -0.270237  0.185361  ...  0.101859 -0.320418 -0.700274   \n",
       "2944 -0.133257 -0.347029  0.007471  ... -0.066249 -0.118854 -0.467179   \n",
       "2945 -0.279610 -0.289477  0.007471  ... -0.046467 -0.205445 -0.617737   \n",
       "2946 -0.218295 -0.229933 -0.111527  ... -0.010386 -0.072237 -0.436940   \n",
       "\n",
       "           554       555       556       557       558       559       560  \n",
       "0     0.006462  0.162920 -0.825886  0.271151 -0.720009  0.276801 -0.057978  \n",
       "1    -0.083495  0.017500 -0.434375  0.920593 -0.698091  0.281343 -0.083898  \n",
       "2    -0.034956  0.202302  0.064103  0.145068 -0.702771  0.280083 -0.079346  \n",
       "3    -0.017067  0.154438  0.340134  0.296407 -0.698954  0.284114 -0.077108  \n",
       "4    -0.002223 -0.040046  0.736715 -0.118545 -0.692245  0.290722 -0.073857  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2942 -0.337422  0.346295  0.884904 -0.698885 -0.651732  0.274627  0.184784  \n",
       "2943 -0.736701 -0.372889 -0.657421  0.322549 -0.655181  0.273578  0.182412  \n",
       "2944 -0.181560  0.088574  0.696663  0.363139 -0.655357  0.274479  0.181184  \n",
       "2945  0.444558 -0.819188  0.929294 -0.008398 -0.659719  0.264782  0.187563  \n",
       "2946  0.598808 -0.287951  0.876030 -0.024965 -0.660080  0.263936  0.188103  \n",
       "\n",
       "[2947 rows x 561 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\n",
    "    'data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt',\n",
    "    sep='\\s+', # white space as delimiter\n",
    "    header=None  # No header row in the file\n",
    ")\n",
    "\n",
    "y_test=pd.read_csv(\n",
    "    'data+scripts/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt',\n",
    "    header=None\n",
    ")\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "LLM Classification: A large dataset of accelerometer readings!\n",
      "\n",
      "To classify these readings into human activities, I'll need to make some assumptions and use my knowledge of machine learning and signal processing. Since I don't have any additional information about the dataset, I'll make the following assumptions:\n",
      "\n",
      "1. The dataset consists of accelerometer readings from a wearable device, such as a smartwatch or fitness tracker.\n",
      "2. The readings are sampled at a constant frequency (e.g., 50 Hz or 100 Hz).\n",
      "3. The activities being performed are typical daily activities, such as walking, running, sitting, standing, etc.\n",
      "\n",
      "Based on these assumptions, I'll use a simple approach to classify the activities. I'll extract some basic features from the data and use a machine learning algorithm to classify the activities.\n",
      "\n",
      "Here are the features I'll extract:\n",
      "\n",
      "1. Mean absolute value (MAV) of the acceleration signal\n",
      "2. Standard deviation of the acceleration signal\n",
      "3. Root mean square (RMS) of the acceleration signal\n",
      "4. Peak acceleration value\n",
      "5. Frequency-domain features (e.g., spectral power in different frequency bands)\n",
      "\n",
      "After extracting these features, I'll use a machine learning algorithm, such as a random forest classifier or a support vector machine (SVM), to classify the activities.\n",
      "\n",
      "Here's a rough classification of the activities based on the features extracted from the dataset:\n",
      "\n",
      "**Activity Classes:**\n",
      "\n",
      "1. **Sitting**: Low MAV, low standard deviation, low RMS, low peak acceleration\n",
      "2. **Standing**: Medium MAV, medium standard deviation, medium RMS, medium peak acceleration\n",
      "3. **Walking**: Medium-high MAV, medium-high standard deviation, medium-high RMS, medium-high peak acceleration\n",
      "4. **Running**: High MAV, high standard deviation, high RMS, high peak acceleration\n",
      "5. **Other** (e.g., jumping, climbing stairs, etc.): High MAV, high standard deviation, high RMS, high peak acceleration, but with distinct patterns in the frequency domain\n",
      "\n",
      "**Classification Results:**\n",
      "\n",
      "After training a random forest classifier on the extracted features, I obtained the following classification results:\n",
      "\n",
      "* Sitting: 23.4%\n",
      "* Standing: 25.1%\n",
      "* Walking: 30.5%\n",
      "* Running: 15.2%\n",
      "* Other: 5.8%\n",
      "\n",
      "Please note that these results are rough estimates and may not be accurate, as the dataset is quite large and complex. A more sophisticated approach, such as using deep learning models or incorporating additional sensors (e.g., gyroscope, magnetometer), may be necessary to achieve higher accuracy.\n",
      "\n",
      "Keep in mind that this is a simplified analysis, and the actual classification results may vary depending on the specific requirements and constraints of the project.\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 5\n",
      "LLM Classification: A large dataset of accelerometer readings!\n",
      "\n",
      "To classify these readings into a specific human activity, I'll need to analyze the patterns and characteristics of the data. Since I don't have any additional information about the data, such as the sampling rate, axis orientation, or the activities being performed, I'll have to rely on general patterns and features that are commonly observed in accelerometer data.\n",
      "\n",
      "After analyzing the data, I've identified some potential patterns and features that could be indicative of different human activities. Here are some possible classifications:\n",
      "\n",
      "**Stationary activities** (e.g., sitting, standing, lying down):\n",
      "\n",
      "* Low amplitude values (close to 0) with minimal variation, indicating minimal movement.\n",
      "* Examples: indices 0-20, 43-50, 63-70, 83-90, 103-110, ...\n",
      "\n",
      "**Walking or running**:\n",
      "\n",
      "* Periodic patterns with higher amplitude values (e.g., -0.5 to 0.5) and a relatively consistent frequency, indicating repetitive movements.\n",
      "* Examples: indices 21-42, 51-62, 71-82, 91-102, 111-120, ...\n",
      "\n",
      "**Upstairs/downstairs or climbing**:\n",
      "\n",
      "* Higher amplitude values with a more irregular pattern, indicating more intense movements.\n",
      "* Examples: indices 121-140, 161-180, 201-220, ...\n",
      "\n",
      "**Jumping or high-impact activities**:\n",
      "\n",
      "* High amplitude values (e.g., > 1 or < -1) with a sudden, brief increase in acceleration, indicating a sudden movement.\n",
      "* Examples: indices 141-160, 181-200, 221-240, ...\n",
      "\n",
      "**Other activities** (e.g., dancing, stretching, or unknown activities):\n",
      "\n",
      "* Unusual patterns or combinations of the above features, indicating a unique activity.\n",
      "* Examples: indices 241-260, 281-300, 321-340, ...\n",
      "\n",
      "Please note that these classifications are based on general patterns and may not be accurate for every individual or specific activity. To improve the accuracy of the classification, additional information about the data and the activities being performed would be necessary.\n",
      "\n",
      "Keep in mind that this is a rough classification, and the actual activities may vary. If you have more information about the data or the activities, I'd be happy to refine the classification.\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 32\n",
      "LLM Classification: A large dataset of accelerometer readings!\n",
      "\n",
      "To classify these readings into human activities, I'll need to make some assumptions and use my knowledge of machine learning and signal processing. Please note that without additional context or information about the data collection process, my classification may not be entirely accurate.\n",
      "\n",
      "Assumptions:\n",
      "\n",
      "1. The data is collected from a wearable device, such as a smartwatch or fitness tracker, with a 3-axis accelerometer (x, y, z).\n",
      "2. The activities are typical daily activities, such as walking, running, sitting, standing, etc.\n",
      "\n",
      "Based on the data, I'll use a simple approach to classify the activities into the following categories:\n",
      "\n",
      "1. **Stationary** (sitting, standing, or lying down)\n",
      "2. **Low-intensity movement** (walking, light exercise)\n",
      "3. **High-intensity movement** (running, jumping, or other high-energy activities)\n",
      "\n",
      "Here's a rough classification of the data:\n",
      "\n",
      "**Stationary** (approx. 30% of the data):\n",
      "\n",
      "* Values close to 0 (e.g., -0.01 to 0.01) indicate minimal movement, suggesting the person is stationary.\n",
      "* Examples: indices 10, 20, 30, 40, ...\n",
      "\n",
      "**Low-intensity movement** (approx. 40% of the data):\n",
      "\n",
      "* Values between -0.5 and 0.5 (e.g., -0.2 to 0.2) indicate gentle movements, such as walking or light exercise.\n",
      "* Examples: indices 50, 60, 70, 80, ...\n",
      "\n",
      "**High-intensity movement** (approx. 30% of the data):\n",
      "\n",
      "* Values with larger magnitudes (e.g., -1.0 to 1.0) indicate more vigorous movements, such as running or jumping.\n",
      "* Examples: indices 100, 120, 140, 160, ...\n",
      "\n",
      "Please note that this is a rough classification and may not be entirely accurate. A more sophisticated approach would involve using machine learning algorithms, such as k-means clustering or support vector machines, to classify the data into specific activities. Additionally, features such as frequency analysis, signal magnitude, and time-domain features could be extracted to improve the classification accuracy.\n",
      "\n",
      "If you have any additional information about the data collection process or would like to refine the classification, please let me know!\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 38\n",
      "LLM Classification: A large dataset of accelerometer readings!\n",
      "\n",
      "To classify these readings into human activities, I'll need to make some assumptions and use my knowledge of machine learning and signal processing. Since I don't have any additional information about the data, I'll make the following assumptions:\n",
      "\n",
      "1. The data is collected from a wearable device, such as a smartwatch or fitness tracker.\n",
      "2. The accelerometer readings are in units of gravity (g) and represent the acceleration of the device in three dimensions (x, y, z).\n",
      "3. The activities being performed are common daily activities, such as walking, running, sitting, standing, etc.\n",
      "\n",
      "Based on these assumptions, I'll use a simple approach to classify the activities. I'll extract some basic features from the data, such as:\n",
      "\n",
      "* Mean and standard deviation of the acceleration values\n",
      "* Peak values and their frequencies\n",
      "* Energy and entropy of the signal\n",
      "\n",
      "Using these features, I'll train a simple machine learning model, such as a decision tree or random forest classifier, to classify the activities.\n",
      "\n",
      "After analyzing the data, I've identified the following activities:\n",
      "\n",
      "**Activity 1: Walking**\n",
      "\n",
      "* Characterized by a regular, periodic pattern with a frequency around 1-2 Hz\n",
      "* Mean acceleration values around 0.5-1.5 g\n",
      "* Standard deviation around 0.5-1.0 g\n",
      "\n",
      "**Activity 2: Running**\n",
      "\n",
      "* Characterized by a faster, more irregular pattern with a frequency around 2-4 Hz\n",
      "* Mean acceleration values around 1.5-3.0 g\n",
      "* Standard deviation around 1.0-2.0 g\n",
      "\n",
      "**Activity 3: Sitting**\n",
      "\n",
      "* Characterized by a low-amplitude, stationary pattern\n",
      "* Mean acceleration values around 0.0-0.5 g\n",
      "* Standard deviation around 0.1-0.5 g\n",
      "\n",
      "**Activity 4: Standing**\n",
      "\n",
      "* Characterized by a low-amplitude, stationary pattern with occasional small movements\n",
      "* Mean acceleration values around 0.0-0.5 g\n",
      "* Standard deviation around 0.1-0.5 g\n",
      "\n",
      "**Activity 5: Other activities (e.g., climbing stairs, jumping, etc.)**\n",
      "\n",
      "* Characterized by irregular, high-amplitude patterns with varying frequencies\n",
      "* Mean acceleration values around 2.0-5.0 g\n",
      "* Standard deviation around 1.0-3.0 g\n",
      "\n",
      "Using these features and a simple machine learning model, I've classified the activities as follows:\n",
      "\n",
      "* Activity 1: Walking (around 20% of the data)\n",
      "* Activity 2: Running (around 15% of the data)\n",
      "* Activity 3: Sitting (around 30% of the data)\n",
      "* Activity 4: Standing (around 20% of the data)\n",
      "* Activity 5: Other activities (around 15% of the data)\n",
      "\n",
      "Please note that this is a rough classification and may not be accurate for all cases. The accuracy of the classification depends on the quality of the data, the features extracted, and the machine learning model used.\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 58\n",
      "LLM Classification: A large dataset of accelerometer readings!\n",
      "\n",
      "To classify these readings into a specific human activity, we'll need to analyze the patterns and characteristics of the data. Since I don't have any additional information about the dataset, I'll make some assumptions and provide a general approach to classify the activities.\n",
      "\n",
      "**Assumptions:**\n",
      "\n",
      "1. The dataset consists of accelerometer readings from a wearable device or a smartphone.\n",
      "2. The readings are sampled at a constant frequency (e.g., 50 Hz or 100 Hz).\n",
      "3. The activities are performed by a single person or a small group of people.\n",
      "\n",
      "**Feature Extraction:**\n",
      "\n",
      "To extract meaningful features from the data, I'll apply the following techniques:\n",
      "\n",
      "1. **Time-domain features:**\n",
      "\t* Mean, standard deviation, variance, and range of the acceleration values.\n",
      "\t* Peak detection: identify the maximum and minimum values in a window of samples.\n",
      "2. **Frequency-domain features:**\n",
      "\t* Fast Fourier Transform (FFT) to extract spectral power density.\n",
      "\t* Calculate the dominant frequency, frequency bandwidth, and spectral centroid.\n",
      "3. **Time-frequency features:**\n",
      "\t* Short-Time Fourier Transform (STFT) to analyze the signal in both time and frequency domains.\n",
      "\n",
      "**Activity Classification:**\n",
      "\n",
      "Using the extracted features, I'll train a machine learning model to classify the activities. Some possible activities that can be inferred from the data are:\n",
      "\n",
      "1. **Walking**\n",
      "2. **Running**\n",
      "3. **Standing**\n",
      "4. **Sitting**\n",
      "5. **Lying down**\n",
      "6. **Climbing stairs**\n",
      "7. **Descending stairs**\n",
      "8. **Jumping**\n",
      "9. **Other activities (e.g., dancing, cycling)**\n",
      "\n",
      "**Machine Learning Model:**\n",
      "\n",
      "I'll use a supervised learning approach, where the model is trained on labeled data. A suitable algorithm for this task could be:\n",
      "\n",
      "1. **Random Forest Classifier**\n",
      "2. **Support Vector Machine (SVM)**\n",
      "3. **K-Nearest Neighbors (KNN)**\n",
      "4. **Convolutional Neural Network (CNN)**\n",
      "\n",
      "**Performance Evaluation:**\n",
      "\n",
      "To evaluate the performance of the model, I'll use metrics such as:\n",
      "\n",
      "1. **Accuracy**\n",
      "2. **Precision**\n",
      "3. **Recall**\n",
      "4. **F1-score**\n",
      "5. **Confusion matrix**\n",
      "\n",
      "Please note that this is a general approach, and the specific features, model, and evaluation metrics may vary depending on the characteristics of the dataset and the specific requirements of the project.\n",
      "\n",
      "If you provide more information about the dataset, such as the sampling frequency, device orientation, and activity labels, I can provide a more detailed analysis and classification approach.\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 65\n",
      "LLM Classification: A large dataset of accelerometer readings!\n",
      "\n",
      "To classify these readings into human activities, I'll need to make some assumptions and use my knowledge of machine learning and signal processing. Since you didn't provide any additional information about the data, I'll make the following assumptions:\n",
      "\n",
      "1. The data is from a single-axis accelerometer (e.g., measuring acceleration in the vertical direction).\n",
      "2. The activities are typical daily activities, such as walking, running, sitting, standing, etc.\n",
      "3. The data is sampled at a relatively high frequency (e.g., 100 Hz or higher).\n",
      "\n",
      "Based on these assumptions, I'll use a simple approach to classify the activities. I'll extract some basic features from the data and use a machine learning algorithm to classify the activities.\n",
      "\n",
      "Here are the features I'll extract:\n",
      "\n",
      "1. Mean absolute value (MAV)\n",
      "2. Standard deviation (STD)\n",
      "3. Root mean square (RMS)\n",
      "4. Peak-to-peak amplitude (PPA)\n",
      "5. Frequency-domain features (e.g., spectral power in different frequency bands)\n",
      "\n",
      "Using these features, I'll train a machine learning model to classify the activities. Since I don't have any labeled data, I'll use an unsupervised learning approach, such as k-means clustering or hierarchical clustering.\n",
      "\n",
      "After analyzing the data, I've identified several clusters that might correspond to different human activities. Here's a rough classification of the data into 6 clusters:\n",
      "\n",
      "**Cluster 1:** Low-magnitude, high-frequency movements (e.g., sitting, standing, or light walking)\n",
      "\n",
      "* Features: Low MAV, STD, and RMS; high PPA; high spectral power in high-frequency bands (> 10 Hz)\n",
      "\n",
      "**Cluster 2:** Medium-magnitude, medium-frequency movements (e.g., walking, jogging, or cycling)\n",
      "\n",
      "* Features: Medium MAV, STD, and RMS; medium PPA; medium spectral power in medium-frequency bands (5-10 Hz)\n",
      "\n",
      "**Cluster 3:** High-magnitude, low-frequency movements (e.g., running, jumping, or heavy exercise)\n",
      "\n",
      "* Features: High MAV, STD, and RMS; low PPA; high spectral power in low-frequency bands (< 5 Hz)\n",
      "\n",
      "**Cluster 4:** Low-magnitude, low-frequency movements (e.g., lying down, sleeping, or relaxing)\n",
      "\n",
      "* Features: Low MAV, STD, and RMS; low PPA; low spectral power in all frequency bands\n",
      "\n",
      "**Cluster 5:** Transient movements (e.g., sudden changes in movement or direction)\n",
      "\n",
      "* Features: High PPA; high spectral power in high-frequency bands (> 10 Hz); irregular patterns in the time domain\n",
      "\n",
      "**Cluster 6:** Noise or artifacts (e.g., sensor noise, electrical interference, or data errors)\n",
      "\n",
      "* Features: High STD and RMS; irregular patterns in the time domain; no clear frequency-domain features\n",
      "\n",
      "Please note that these clusters are not definitive and might not correspond to specific activities. The classification is based on the patterns and features extracted from the data, but it may require additional information or labeled data to improve the accuracy of the classification.\n",
      "\n",
      "Keep in mind that this is a rough analysis, and the results might not be perfect. If you have any additional information about the data or the activities, I'd be happy to refine the analysis and provide more accurate results.\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexes = [0, 5, 32, 38, 58, 65]\n",
    "\n",
    "for index in indexes:\n",
    "    # Convert the row to a string representation\n",
    "    data_str = X_train.iloc[index].to_string()\n",
    "    query = f\"Classify the following accelerometer data into the correct human activity: {data_str}\"\n",
    "    \n",
    "    # Initialize and use the language model\n",
    "    model_name = \"llama3-70b\"  # Model name\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"LLM Classification: {answer.content.strip()}\")\n",
    "    print(f\"Actual Label: {y_train.iloc[index].values[0]}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample indexes from your training set\n",
    "indexes = [0, 5, 32, 38, 58, 65]\n",
    "\n",
    "# Function to get a random subset of row data\n",
    "def get_random_subset(row, subset_size=10):\n",
    "    \"\"\"Returns a random subset of 'subset_size' elements from a row.\"\"\"\n",
    "    return row.sample(n=subset_size, random_state=1)\n",
    "\n",
    "# Prepare few-shot training examples using a small subset of each row\n",
    "few_shot_examples = []\n",
    "for index in indexes:\n",
    "    # Select a random subset of the row\n",
    "    subset_data = get_random_subset(X_train.iloc[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    actual_label = y_train.iloc[index].values[0]\n",
    "    few_shot_examples.append(f\"Data: {data_str}\\nLabel: {actual_label}\")\n",
    "\n",
    "# Concatenate the few-shot examples for the prompt\n",
    "few_shot_prompt = \"\\n\\n\".join(few_shot_examples)\n",
    "\n",
    "# Test the model on new data\n",
    "test_indexes = [10, 15, 40, 100]  # Sample indexes from your test set\n",
    "for index in test_indexes:\n",
    "    # Select a random subset of the test row\n",
    "    subset_data = get_random_subset(X_test.iloc[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    query = f\"{few_shot_prompt}\\n\\nClassify the following accelerometer data into the correct human activity: {data_str}\"\n",
    "    \n",
    "    # Initialize and use the language model\n",
    "    model_name = \"llama3-70b\"  # Model name\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"LLM Classification: {answer.content.strip()}\")\n",
    "    print(f\"Actual Label: {y_test.iloc[index].values[0]}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 10\n",
      "LLM Classification: Based on the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the new data and the provided training data, I'm going to make a prediction.\n",
      "\n",
      "Here's the classification:\n",
      "\n",
      "Label: 5\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 15\n",
      "LLM Classification: Based on the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and correlations in the training data, I'll make a prediction for the new data.\n",
      "\n",
      "Here's the classification:\n",
      "\n",
      "Label: 4\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 53\n",
      "LLM Classification: Based on the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and correlations in the training data, I'll make a prediction for the new data.\n",
      "\n",
      "Here's the classification:\n",
      "\n",
      "Label: 6\n",
      "\n",
      "This prediction is based on the similarity of the new data to the patterns observed in the training data, particularly in the ranges and distributions of the values.\n",
      "Actual Label: 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 70\n",
      "LLM Classification: Based on the provided data, I'll classify the given accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the given data and the training data, I predict that the correct classification is:\n",
      "\n",
      "Label: 5\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 100\n",
      "LLM Classification: Based on the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the new data and the provided training data, I'm going to make a prediction.\n",
      "\n",
      "Here's the classification:\n",
      "Label: 1\n",
      "\n",
      "This prediction is based on the similarities in the patterns and values of the new data with the training data labeled as 1.\n",
      "Actual Label: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 205\n",
      "LLM Classification: Based on the provided data, I'll classify the given accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the given data and the training data, I predict that the correct classification is:\n",
      "\n",
      "Label: 0    5\n",
      "\n",
      "This classification is based on the similarity in patterns and values between the given data and the training data labeled as 0    5.\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 207\n",
      "LLM Classification: Based on the provided data, I'll classify the given accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the given data and the training data, I predict that the correct classification is:\n",
      "\n",
      "Label: 0    5\n",
      "\n",
      "This classification is based on the similarity in patterns and values between the given data and the training data labeled as 0    5.\n",
      "Actual Label: 6\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 302\n",
      "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the new data and the provided training data, I predict that the new data belongs to:\n",
      "\n",
      "Label: 4\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 310\n",
      "LLM Classification: Based on the provided data, I'll classify the given accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the given data and the training data, I predict that the correct classification is:\n",
      "\n",
      "Label: 0    4\n",
      "\n",
      "This classification is based on the similarities in the patterns of the accelerometer data, particularly in the values of the 47, 439, 355, and 532 features, which are similar to those in the training data with Label 0 and Name 32 or 38.\n",
      "Actual Label: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Index: 440\n",
      "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
      "\n",
      "After analyzing the patterns and similarities between the new data and the provided training data, I predict that the new data belongs to:\n",
      "\n",
      "Label: 6\n",
      "Actual Label: 2\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "# 2 indices of the same activity label provided (5,4,6,1)\n",
    "indexes = [0, 5, 32, 38, 58, 65, 253, 449]\n",
    "\n",
    "# Function to get a random subset of row data\n",
    "def get_random_subset(row, subset_size=10):\n",
    "    \"\"\"Returns a random subset of 'subset_size' elements from a row.\"\"\"\n",
    "    return row.sample(n=subset_size, random_state=1)\n",
    "\n",
    "# Prepare few-shot training examples using a small subset of each row\n",
    "few_shot_examples = []\n",
    "for index in indexes:\n",
    "    # Select a random subset of the row\n",
    "    subset_data = get_random_subset(X_train.iloc[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    actual_label = y_train.iloc[index]\n",
    "    few_shot_examples.append(f\"Data: {data_str}\\nLabel: {actual_label}\")\n",
    "\n",
    "# Concatenate the few-shot examples for the prompt\n",
    "few_shot_prompt = \"\\n\\n\".join(few_shot_examples)\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "\n",
    "# Train a Decision Tree model using the entire training set\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on new data using both Few-Shot Learning and Decision Tree\n",
    "test_indexes = [10, 15, 53, 70, 100, 205, 207,302,310,440  ] # (5, 5,6,6,1,4,4,3,2,1)\n",
    "\n",
    "# Initialize lists to store predictions\n",
    "few_shot_predictions = []\n",
    "decision_tree_predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "def extract_label(llm_response):\n",
    "    \"\"\"Extract the predicted label from the LLM response.\"\"\"\n",
    "    match = re.search(r'Label: (\\d+)', llm_response)  # The '(?i)' makes the search case-insensitive\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "for index in test_indexes:\n",
    "    # Select a random subset of the test row\n",
    "    subset_data = get_random_subset(X_test.iloc[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    query = (f\"{few_shot_prompt}\\n\\n\"\n",
    "             f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
    "             f\"Data: {data_str}\\n\\n\"\n",
    "             \"Please provide the classification in the following format:\\n\"\n",
    "             \"Label: <predicted_label>\")\n",
    "\n",
    "    # Initialize and use the language model\n",
    "    model_name = \"llama3-70b\"  # Model name\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"LLM Classification: {answer.content.strip()}\")\n",
    "    print(f\"Actual Label: {y_test.iloc[index].values[0]}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decision_tree_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     actual_labels\u001b[38;5;241m.\u001b[39mappend(y_test\u001b[38;5;241m.\u001b[39miloc[index]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Decision Tree prediction\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     decision_tree_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mdecision_tree_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict([X_test\u001b[38;5;241m.\u001b[39miloc[index]])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     64\u001b[0m     decision_tree_predictions\u001b[38;5;241m.\u001b[39mappend(decision_tree_prediction)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Convert lists to numpy arrays for easier calculation\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decision_tree_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Define the extract_label function\n",
    "def extract_label(llm_response):\n",
    "    \"\"\"Extract the predicted label from the LLM response.\"\"\"\n",
    "    match = re.search(r'(?i)label: (\\d+)', llm_response)  # The '(?i)' makes the search case-insensitive\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Sample indexes from your training set\n",
    "indexes = [0, 5, 32, 38, 58, 65]\n",
    "\n",
    "# Function to get a random subset of row data\n",
    "def get_random_subset(row, subset_size=10):\n",
    "    \"\"\"Returns a random subset of 'subset_size' elements from a row.\"\"\"\n",
    "    return row.sample(n=subset_size, random_state=1)\n",
    "\n",
    "# Prepare few-shot training examples using a small subset of each row\n",
    "few_shot_examples = []\n",
    "for index in indexes:\n",
    "    # Select a random subset of the row\n",
    "    subset_data = get_random_subset(X_train.iloc[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    actual_label = y_train.iloc[index].values[0]\n",
    "    few_shot_examples.append(f\"Data: {data_str}\\nLabel: {actual_label}\")\n",
    "\n",
    "# Concatenate the few-shot examples for the prompt\n",
    "few_shot_prompt = \"\\n\\n\".join(few_shot_examples)\n",
    "\n",
    "# Lists to store results\n",
    "llm_predictions = []\n",
    "decision_tree_predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "# Test the model on new data\n",
    "test_indexes = [10, 15, 40, 100]  # Sample indexes from your test set\n",
    "for index in test_indexes:\n",
    "    # Select a random subset of the test row\n",
    "    subset_data = get_random_subset(X_test.iloc[index])\n",
    "    data_str = subset_data.to_string()\n",
    "    query = (f\"{few_shot_prompt}\\n\\n\"\n",
    "             f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
    "             f\"Data: {data_str}\\n\\n\"\n",
    "             \"Please provide the classification in the following format:\\n\"\n",
    "             \"Label: <predicted_label>\")\n",
    "    \n",
    "    # Initialize and use the language model\n",
    "    model_name = \"llama3-70b\"  # Model name\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # Extract the LLM prediction\n",
    "    llm_label = extract_label(answer.content.strip())\n",
    "    \n",
    "    # Store LLM prediction and actual label\n",
    "    llm_predictions.append(llm_label)\n",
    "    actual_labels.append(y_test.iloc[index].values[0])\n",
    "    \n",
    "    # Decision Tree prediction\n",
    "    decision_tree_prediction = decision_tree_model.predict([X_test.iloc[index]])[0]\n",
    "    decision_tree_predictions.append(decision_tree_prediction)\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculation\n",
    "llm_predictions = np.array(llm_predictions)\n",
    "decision_tree_predictions = np.array(decision_tree_predictions)\n",
    "actual_labels = np.array(actual_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(predictions, actuals):\n",
    "    \"\"\"Calculate the accuracy of predictions compared to actual labels.\"\"\"\n",
    "    correct_predictions = np.sum(predictions == actuals)\n",
    "    accuracy = correct_predictions / len(actuals)\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracies\n",
    "llm_accuracy = calculate_accuracy(llm_predictions, actual_labels)\n",
    "decision_tree_accuracy = calculate_accuracy(decision_tree_predictions, actual_labels)\n",
    "\n",
    "# Print results\n",
    "print(f\"Few-Shot Learning Accuracy: {llm_accuracy:.2f}\")\n",
    "print(f\"Decision Tree Accuracy: {decision_tree_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
